{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c391b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastf1 as ff\n",
    "import logging\n",
    "logging.getLogger(\"fastf1\").setLevel(logging.ERROR)\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9758e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_session(job_info):\n",
    "    year, event, session_type = job_info\n",
    "    try:\n",
    "        session = ff.get_session(year, event, session_type)\n",
    "        session.load(laps=True, telemetry=False, weather=True, messages=False)\n",
    "        \n",
    "        laps = session.laps\n",
    "        weather = session.weather_data\n",
    "\n",
    "        laps = laps.sort_values('Time')\n",
    "        weather = weather.sort_values('Time')\n",
    "\n",
    "        laps_with_weather = pd.merge_asof(\n",
    "            left=laps,\n",
    "            right=weather,\n",
    "            on='Time'\n",
    "        )\n",
    "\n",
    "        clean_laps = laps_with_weather.loc[laps_with_weather['IsAccurate'] == True].copy()\n",
    "        clean_laps = clean_laps.dropna(subset=['LapTime'])\n",
    "        clean_laps['EventName'] = event\n",
    "        clean_laps['Year'] = year\n",
    "        \n",
    "        return clean_laps\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f5b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 149 sessions in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [01:05<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully gathered 139523 clean laps. Saving to CSV...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "jobs = []\n",
    "for year in [2024, 2023, 2022, 2021, 2020, 2019, 2018]:\n",
    "    schedule = ff.get_event_schedule(year, include_testing=False)\n",
    "    for event in schedule['EventName']:\n",
    "        jobs.append((year, event, 'R'))\n",
    "\n",
    "print(f\"Starting to process {len(jobs)} sessions in parallel...\")\n",
    "results = Parallel(n_jobs=-1)(delayed(process_session)(job) for job in tqdm(jobs))\n",
    "\n",
    "all_results = [res for res in results if res is not None]\n",
    "final_dataset = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "print(f\"Successfully gathered {len(final_dataset)} clean laps. Saving to CSV...\")\n",
    "final_dataset.to_csv('Formula_1_Data_2018-24.csv', index=False)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d73b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Formula_1_Data_2018-24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de62b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Deleted','DeletedReason','LapStartDate','PitOutTime','PitInTime'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e472b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139523, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a34696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 12, 21,  2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TrackStatus'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526b05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['FastF1Generated','IsAccurate'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = [\n",
    "    'DriverNumber','FreshTyre','Team','SpeedI1','SpeedI2','SpeedST',\n",
    "    'SpeedFL','Time','LapStartTime', 'Sector1SessionTime', 'Sector2SessionTime',\n",
    "    'Sector3SessionTime', 'LapTime', 'Sector1Time', 'Sector2Time', 'Sector3Time',\n",
    "    'IsPersonalBest','Position','TrackStatus'        \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c85df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LapTime(s)'] = pd.to_timedelta(df['LapTime']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TyreLife'] = df.groupby(['Driver','EventName'])['TyreLife'].transform(lambda x : x.fillna(x.median()))\n",
    "df['Stint'] = df.groupby(['Driver','EventName'])['Stint'].transform(lambda x : x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e21f394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Compound'] = df.groupby(['Driver', 'EventName'])['Compound'].transform(lambda x: x.fillna(x.mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0cdd796",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.drop(columns = dropped_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c5a9bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139523 entries, 0 to 139522\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Driver         139523 non-null  object \n",
      " 1   LapNumber      139523 non-null  float64\n",
      " 2   Stint          139523 non-null  float64\n",
      " 3   Compound       139523 non-null  object \n",
      " 4   TyreLife       139523 non-null  float64\n",
      " 5   AirTemp        139523 non-null  float64\n",
      " 6   Humidity       139523 non-null  float64\n",
      " 7   Pressure       139523 non-null  float64\n",
      " 8   Rainfall       139523 non-null  bool   \n",
      " 9   TrackTemp      139523 non-null  float64\n",
      " 10  WindDirection  139523 non-null  int64  \n",
      " 11  WindSpeed      139523 non-null  float64\n",
      " 12  EventName      139523 non-null  object \n",
      " 13  Year           139523 non-null  int64  \n",
      " 14  LapTime(s)     139523 non-null  float64\n",
      "dtypes: bool(1), float64(9), int64(2), object(3)\n",
      "memory usage: 15.0+ MB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e319c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Rainfall'] = final_df['Rainfall'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "efe8a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Driver', 'Compound']\n",
    "final_df_encoded = pd.get_dummies(final_df, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ae2a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = final_df_encoded.select_dtypes(include='bool').columns\n",
    "final_df_encoded[bool_cols] = final_df_encoded[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13e17c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_encoded.to_csv(\"TrainingDataF1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b62dd6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "\n",
    "def train_and_evaluate_circuit(df, circuit_name):\n",
    "    print(f\"--- Processing: {circuit_name} ---\")\n",
    "    \n",
    "    circuit_df = df[df['EventName'] == circuit_name].copy()\n",
    "    \n",
    "    if len(circuit_df) < 500:\n",
    "        print(f\"Skipping {circuit_name}, not enough data.\\n\")\n",
    "        return None\n",
    "\n",
    "    y = circuit_df['LapTime(s)']\n",
    "    X = circuit_df.drop(columns=['LapTime(s)', 'EventName'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        'XGBoost': xgb.XGBRegressor(random_state=42),\n",
    "        'LightGBM': lgb.LGBMRegressor(random_state=42)\n",
    "    }\n",
    "    \n",
    "    circuit_results = {'Circuit': circuit_name}\n",
    "    trained_models = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"  Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        circuit_results[f'{name}_RMSE'] = rmse\n",
    "        circuit_results[f'{name}_R2'] = r2\n",
    "        trained_models[name] = model\n",
    "\n",
    "    best_model_name = 'XGBoost' if circuit_results['XGBoost_RMSE'] <= circuit_results['LightGBM_RMSE'] else 'LightGBM'\n",
    "    circuit_results['Best_Model'] = best_model_name\n",
    "    \n",
    "    print(f\"  -> Best Model: {best_model_name} (RMSE: {circuit_results[f'{best_model_name}_RMSE']:.3f})\")\n",
    "\n",
    "    best_model_object = trained_models[best_model_name]\n",
    "    safe_filename = re.sub(r'[\\\\/*?:\"<>|]', \"\", circuit_name).replace(\" \", \"_\")\n",
    "    model_filename = f'models/{safe_filename}_model.joblib'\n",
    "    joblib.dump(best_model_object, model_filename)\n",
    "    print(f\"  -> Model saved as {model_filename}\\n\")\n",
    "    \n",
    "    return circuit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "304f7f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed dataset...\n",
      "Dataset loaded.\n",
      "--- Processing: Bahrain Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 4940, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 97.395866\n",
      "  -> Best Model: XGBoost (RMSE: 0.700)\n",
      "  -> Model saved as models/Bahrain_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Saudi Arabian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 461\n",
      "[LightGBM] [Info] Number of data points in the train set: 2258, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 94.992246\n",
      "  -> Best Model: XGBoost (RMSE: 0.798)\n",
      "  -> Model saved as models/Saudi_Arabian_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Australian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 685\n",
      "[LightGBM] [Info] Number of data points in the train set: 3320, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 85.911940\n",
      "  -> Best Model: XGBoost (RMSE: 0.686)\n",
      "  -> Model saved as models/Australian_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Japanese Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Number of data points in the train set: 2867, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 98.251411\n",
      "  -> Best Model: XGBoost (RMSE: 1.213)\n",
      "  -> Model saved as models/Japanese_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Chinese Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 470\n",
      "[LightGBM] [Info] Number of data points in the train set: 1702, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 100.002446\n",
      "  -> Best Model: LightGBM (RMSE: 0.683)\n",
      "  -> Model saved as models/Chinese_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Miami Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 466\n",
      "[LightGBM] [Info] Number of data points in the train set: 2312, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 93.478155\n",
      "  -> Best Model: LightGBM (RMSE: 0.514)\n",
      "  -> Model saved as models/Miami_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Emilia Romagna Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 623\n",
      "[LightGBM] [Info] Number of data points in the train set: 3192, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score 82.929867\n",
      "  -> Best Model: XGBoost (RMSE: 1.180)\n",
      "  -> Model saved as models/Emilia_Romagna_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Monaco Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 6149, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 80.475032\n",
      "  -> Best Model: LightGBM (RMSE: 1.552)\n",
      "  -> Model saved as models/Monaco_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Canadian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 4426, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 79.194268\n",
      "  -> Best Model: LightGBM (RMSE: 0.776)\n",
      "  -> Model saved as models/Canadian_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Spanish Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 930\n",
      "[LightGBM] [Info] Number of data points in the train set: 6168, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 83.449825\n",
      "  -> Best Model: XGBoost (RMSE: 1.353)\n",
      "  -> Model saved as models/Spanish_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Austrian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 892\n",
      "[LightGBM] [Info] Number of data points in the train set: 6429, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 70.565676\n",
      "  -> Best Model: LightGBM (RMSE: 1.377)\n",
      "  -> Model saved as models/Austrian_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: British Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 882\n",
      "[LightGBM] [Info] Number of data points in the train set: 4260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 93.566553\n",
      "  -> Best Model: LightGBM (RMSE: 1.152)\n",
      "  -> Model saved as models/British_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Hungarian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 6426, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 83.801394\n",
      "  -> Best Model: LightGBM (RMSE: 0.738)\n",
      "  -> Model saved as models/Hungarian_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Belgian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 713\n",
      "[LightGBM] [Info] Number of data points in the train set: 3227, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score 111.230667\n",
      "  -> Best Model: XGBoost (RMSE: 0.643)\n",
      "  -> Model saved as models/Belgian_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Dutch Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 659\n",
      "[LightGBM] [Info] Number of data points in the train set: 3830, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 77.036763\n",
      "  -> Best Model: XGBoost (RMSE: 0.712)\n",
      "  -> Model saved as models/Dutch_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Italian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 4632, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score 86.146798\n",
      "  -> Best Model: LightGBM (RMSE: 0.846)\n",
      "  -> Model saved as models/Italian_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Azerbaijan Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 806\n",
      "[LightGBM] [Info] Number of data points in the train set: 3727, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 108.481337\n",
      "  -> Best Model: XGBoost (RMSE: 0.980)\n",
      "  -> Model saved as models/Azerbaijan_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Singapore Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 565\n",
      "[LightGBM] [Info] Number of data points in the train set: 3728, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 105.728860\n",
      "  -> Best Model: LightGBM (RMSE: 0.995)\n",
      "  -> Model saved as models/Singapore_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: United States Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 4261, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score 101.867619\n",
      "  -> Best Model: LightGBM (RMSE: 0.767)\n",
      "  -> Model saved as models/United_States_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Mexico City Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 670\n",
      "[LightGBM] [Info] Number of data points in the train set: 3693, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 83.334831\n",
      "  -> Best Model: LightGBM (RMSE: 1.111)\n",
      "  -> Model saved as models/Mexico_City_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: São Paulo Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 598\n",
      "[LightGBM] [Info] Number of data points in the train set: 3185, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 78.218202\n",
      "  -> Best Model: LightGBM (RMSE: 1.355)\n",
      "  -> Model saved as models/São_Paulo_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Las Vegas Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 305\n",
      "[LightGBM] [Info] Number of data points in the train set: 1251, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 98.693170\n",
      "  -> Best Model: XGBoost (RMSE: 0.650)\n",
      "  -> Model saved as models/Las_Vegas_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Qatar Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 460\n",
      "[LightGBM] [Info] Number of data points in the train set: 2030, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 88.110791\n",
      "  -> Best Model: LightGBM (RMSE: 0.676)\n",
      "  -> Model saved as models/Qatar_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Abu Dhabi Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 5246, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score 96.154186\n",
      "  -> Best Model: LightGBM (RMSE: 0.565)\n",
      "  -> Model saved as models/Abu_Dhabi_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: French Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 687\n",
      "[LightGBM] [Info] Number of data points in the train set: 2821, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score 98.607657\n",
      "  -> Best Model: LightGBM (RMSE: 0.625)\n",
      "  -> Model saved as models/French_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Portuguese Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 520\n",
      "[LightGBM] [Info] Number of data points in the train set: 1842, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 82.998009\n",
      "  -> Best Model: LightGBM (RMSE: 0.701)\n",
      "  -> Model saved as models/Portuguese_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Styrian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 492\n",
      "[LightGBM] [Info] Number of data points in the train set: 1879, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 70.007983\n",
      "  -> Best Model: LightGBM (RMSE: 0.568)\n",
      "  -> Model saved as models/Styrian_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Russian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 700\n",
      "[LightGBM] [Info] Number of data points in the train set: 2675, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score 101.094671\n",
      "  -> Best Model: LightGBM (RMSE: 1.022)\n",
      "  -> Model saved as models/Russian_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Turkish Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 456\n",
      "[LightGBM] [Info] Number of data points in the train set: 1617, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 100.189654\n",
      "  -> Best Model: LightGBM (RMSE: 1.405)\n",
      "  -> Model saved as models/Turkish_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: 70th Anniversary Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 737, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 92.440364\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "  -> Best Model: XGBoost (RMSE: 0.798)\n",
      "  -> Model saved as models/70th_Anniversary_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Tuscan Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 237\n",
      "[LightGBM] [Info] Number of data points in the train set: 444, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 83.532056\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "  -> Best Model: XGBoost (RMSE: 0.842)\n",
      "  -> Model saved as models/Tuscan_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Eifel Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 285\n",
      "[LightGBM] [Info] Number of data points in the train set: 668, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 92.846626\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "  -> Best Model: LightGBM (RMSE: 0.685)\n",
      "  -> Model saved as models/Eifel_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Sakhir Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 312\n",
      "[LightGBM] [Info] Number of data points in the train set: 965, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 58.442546\n",
      "  -> Best Model: LightGBM (RMSE: 0.394)\n",
      "  -> Model saved as models/Sakhir_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: German Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 427\n",
      "[LightGBM] [Info] Number of data points in the train set: 968, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 84.481215\n",
      "  -> Best Model: LightGBM (RMSE: 2.029)\n",
      "  -> Model saved as models/German_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Mexican Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 538\n",
      "[LightGBM] [Info] Number of data points in the train set: 1860, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 82.712385\n",
      "  -> Best Model: XGBoost (RMSE: 0.833)\n",
      "  -> Model saved as models/Mexican_Grand_Prix_model.joblib\n",
      "\n",
      "--- Processing: Brazilian Grand Prix ---\n",
      "  Training XGBoost...\n",
      "  Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 562\n",
      "[LightGBM] [Info] Number of data points in the train set: 1868, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 74.339083\n",
      "  -> Best Model: LightGBM (RMSE: 1.071)\n",
      "  -> Model saved as models/Brazilian_Grand_Prix_model.joblib\n",
      "\n",
      "--- All circuits processed. ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "\n",
    "    print(\"Loading preprocessed dataset...\")\n",
    "    try:\n",
    "        full_df = pd.read_csv('TrainingDataF1.csv')\n",
    "        print(\"Dataset loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERROR: Preprocessed CSV file not found.\")\n",
    "        exit()\n",
    "\n",
    "    if 'Unnamed: 0' in full_df.columns:\n",
    "        full_df = full_df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    bool_cols = full_df.select_dtypes(include='bool').columns\n",
    "    full_df[bool_cols] = full_df[bool_cols].astype(int)\n",
    "\n",
    "    circuits = full_df['EventName'].unique()\n",
    "    \n",
    "    all_results_list = []\n",
    "\n",
    "    for circuit in circuits:\n",
    "        results = train_and_evaluate_circuit(full_df, circuit)\n",
    "        if results is not None:\n",
    "            all_results_list.append(results)\n",
    "        \n",
    "    print(\"--- All circuits processed. ---\")\n",
    "\n",
    "    results_df = pd.DataFrame(all_results_list)\n",
    "\n",
    "    avg_rmse = results_df.apply(lambda row: row[f\"{row['Best_Model']}_RMSE\"], axis=1).mean()\n",
    "    avg_r2 = results_df.apply(lambda row: row[f\"{row['Best_Model']}_R2\"], axis=1).mean()\n",
    "\n",
    "    final_summary = {\n",
    "        \"total_models_trained\": len(results_df),\n",
    "        \"average_rmse\": avg_rmse,\n",
    "        \"average_r2\": avg_r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ec6dc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance by Circuit ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Circuit</th>\n",
       "      <th>XGBoost_RMSE</th>\n",
       "      <th>XGBoost_R2</th>\n",
       "      <th>LightGBM_RMSE</th>\n",
       "      <th>LightGBM_R2</th>\n",
       "      <th>Best_Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bahrain Grand Prix</td>\n",
       "      <td>0.700314</td>\n",
       "      <td>0.863391</td>\n",
       "      <td>0.711977</td>\n",
       "      <td>0.858803</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saudi Arabian Grand Prix</td>\n",
       "      <td>0.798139</td>\n",
       "      <td>0.792485</td>\n",
       "      <td>0.911358</td>\n",
       "      <td>0.729435</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>0.686099</td>\n",
       "      <td>0.958616</td>\n",
       "      <td>0.706368</td>\n",
       "      <td>0.956135</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese Grand Prix</td>\n",
       "      <td>1.213372</td>\n",
       "      <td>0.930551</td>\n",
       "      <td>1.283383</td>\n",
       "      <td>0.922305</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chinese Grand Prix</td>\n",
       "      <td>0.693838</td>\n",
       "      <td>0.845481</td>\n",
       "      <td>0.682511</td>\n",
       "      <td>0.850484</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Miami Grand Prix</td>\n",
       "      <td>0.523080</td>\n",
       "      <td>0.859556</td>\n",
       "      <td>0.513824</td>\n",
       "      <td>0.864483</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Emilia Romagna Grand Prix</td>\n",
       "      <td>1.179796</td>\n",
       "      <td>0.941789</td>\n",
       "      <td>1.218983</td>\n",
       "      <td>0.937857</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monaco Grand Prix</td>\n",
       "      <td>1.589533</td>\n",
       "      <td>0.936413</td>\n",
       "      <td>1.552192</td>\n",
       "      <td>0.939366</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Canadian Grand Prix</td>\n",
       "      <td>1.385556</td>\n",
       "      <td>0.916481</td>\n",
       "      <td>0.775564</td>\n",
       "      <td>0.973832</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Spanish Grand Prix</td>\n",
       "      <td>1.352841</td>\n",
       "      <td>0.838161</td>\n",
       "      <td>1.404804</td>\n",
       "      <td>0.825490</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Austrian Grand Prix</td>\n",
       "      <td>1.508823</td>\n",
       "      <td>0.578906</td>\n",
       "      <td>1.376727</td>\n",
       "      <td>0.649412</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>British Grand Prix</td>\n",
       "      <td>1.389555</td>\n",
       "      <td>0.871143</td>\n",
       "      <td>1.152336</td>\n",
       "      <td>0.911383</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hungarian Grand Prix</td>\n",
       "      <td>0.748003</td>\n",
       "      <td>0.829901</td>\n",
       "      <td>0.737922</td>\n",
       "      <td>0.834455</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Belgian Grand Prix</td>\n",
       "      <td>0.642694</td>\n",
       "      <td>0.929343</td>\n",
       "      <td>0.670209</td>\n",
       "      <td>0.923163</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dutch Grand Prix</td>\n",
       "      <td>0.712159</td>\n",
       "      <td>0.959088</td>\n",
       "      <td>0.896680</td>\n",
       "      <td>0.935140</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Italian Grand Prix</td>\n",
       "      <td>0.859768</td>\n",
       "      <td>0.933692</td>\n",
       "      <td>0.845996</td>\n",
       "      <td>0.935799</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Azerbaijan Grand Prix</td>\n",
       "      <td>0.979924</td>\n",
       "      <td>0.852763</td>\n",
       "      <td>1.096819</td>\n",
       "      <td>0.815540</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Singapore Grand Prix</td>\n",
       "      <td>1.015622</td>\n",
       "      <td>0.978296</td>\n",
       "      <td>0.995336</td>\n",
       "      <td>0.979154</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>United States Grand Prix</td>\n",
       "      <td>0.804730</td>\n",
       "      <td>0.806309</td>\n",
       "      <td>0.767368</td>\n",
       "      <td>0.823877</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mexico City Grand Prix</td>\n",
       "      <td>1.372977</td>\n",
       "      <td>0.824930</td>\n",
       "      <td>1.111145</td>\n",
       "      <td>0.885336</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>São Paulo Grand Prix</td>\n",
       "      <td>1.497180</td>\n",
       "      <td>0.905878</td>\n",
       "      <td>1.355075</td>\n",
       "      <td>0.922897</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Las Vegas Grand Prix</td>\n",
       "      <td>0.649935</td>\n",
       "      <td>0.823923</td>\n",
       "      <td>0.650328</td>\n",
       "      <td>0.823710</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Qatar Grand Prix</td>\n",
       "      <td>0.689711</td>\n",
       "      <td>0.899515</td>\n",
       "      <td>0.675501</td>\n",
       "      <td>0.903613</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Abu Dhabi Grand Prix</td>\n",
       "      <td>0.578444</td>\n",
       "      <td>0.993242</td>\n",
       "      <td>0.565012</td>\n",
       "      <td>0.993553</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>French Grand Prix</td>\n",
       "      <td>0.640580</td>\n",
       "      <td>0.893997</td>\n",
       "      <td>0.624795</td>\n",
       "      <td>0.899156</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Portuguese Grand Prix</td>\n",
       "      <td>0.717980</td>\n",
       "      <td>0.765345</td>\n",
       "      <td>0.700862</td>\n",
       "      <td>0.776401</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Styrian Grand Prix</td>\n",
       "      <td>0.931581</td>\n",
       "      <td>0.517340</td>\n",
       "      <td>0.568292</td>\n",
       "      <td>0.820385</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Russian Grand Prix</td>\n",
       "      <td>1.187672</td>\n",
       "      <td>0.820455</td>\n",
       "      <td>1.021635</td>\n",
       "      <td>0.867147</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Turkish Grand Prix</td>\n",
       "      <td>1.544040</td>\n",
       "      <td>0.944235</td>\n",
       "      <td>1.405239</td>\n",
       "      <td>0.953810</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>70th Anniversary Grand Prix</td>\n",
       "      <td>0.798335</td>\n",
       "      <td>0.703501</td>\n",
       "      <td>0.845582</td>\n",
       "      <td>0.667368</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Tuscan Grand Prix</td>\n",
       "      <td>0.842235</td>\n",
       "      <td>0.844375</td>\n",
       "      <td>0.850806</td>\n",
       "      <td>0.841192</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Eifel Grand Prix</td>\n",
       "      <td>0.699898</td>\n",
       "      <td>0.818247</td>\n",
       "      <td>0.685291</td>\n",
       "      <td>0.825754</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Sakhir Grand Prix</td>\n",
       "      <td>0.410202</td>\n",
       "      <td>0.786357</td>\n",
       "      <td>0.394023</td>\n",
       "      <td>0.802878</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>German Grand Prix</td>\n",
       "      <td>2.061848</td>\n",
       "      <td>0.914527</td>\n",
       "      <td>2.029391</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Mexican Grand Prix</td>\n",
       "      <td>0.833429</td>\n",
       "      <td>0.790207</td>\n",
       "      <td>0.834176</td>\n",
       "      <td>0.789830</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Brazilian Grand Prix</td>\n",
       "      <td>1.078337</td>\n",
       "      <td>0.524845</td>\n",
       "      <td>1.070953</td>\n",
       "      <td>0.531330</td>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Circuit  XGBoost_RMSE  XGBoost_R2  LightGBM_RMSE  \\\n",
       "0            Bahrain Grand Prix      0.700314    0.863391       0.711977   \n",
       "1      Saudi Arabian Grand Prix      0.798139    0.792485       0.911358   \n",
       "2         Australian Grand Prix      0.686099    0.958616       0.706368   \n",
       "3           Japanese Grand Prix      1.213372    0.930551       1.283383   \n",
       "4            Chinese Grand Prix      0.693838    0.845481       0.682511   \n",
       "5              Miami Grand Prix      0.523080    0.859556       0.513824   \n",
       "6     Emilia Romagna Grand Prix      1.179796    0.941789       1.218983   \n",
       "7             Monaco Grand Prix      1.589533    0.936413       1.552192   \n",
       "8           Canadian Grand Prix      1.385556    0.916481       0.775564   \n",
       "9            Spanish Grand Prix      1.352841    0.838161       1.404804   \n",
       "10          Austrian Grand Prix      1.508823    0.578906       1.376727   \n",
       "11           British Grand Prix      1.389555    0.871143       1.152336   \n",
       "12         Hungarian Grand Prix      0.748003    0.829901       0.737922   \n",
       "13           Belgian Grand Prix      0.642694    0.929343       0.670209   \n",
       "14             Dutch Grand Prix      0.712159    0.959088       0.896680   \n",
       "15           Italian Grand Prix      0.859768    0.933692       0.845996   \n",
       "16        Azerbaijan Grand Prix      0.979924    0.852763       1.096819   \n",
       "17         Singapore Grand Prix      1.015622    0.978296       0.995336   \n",
       "18     United States Grand Prix      0.804730    0.806309       0.767368   \n",
       "19       Mexico City Grand Prix      1.372977    0.824930       1.111145   \n",
       "20         São Paulo Grand Prix      1.497180    0.905878       1.355075   \n",
       "21         Las Vegas Grand Prix      0.649935    0.823923       0.650328   \n",
       "22             Qatar Grand Prix      0.689711    0.899515       0.675501   \n",
       "23         Abu Dhabi Grand Prix      0.578444    0.993242       0.565012   \n",
       "24            French Grand Prix      0.640580    0.893997       0.624795   \n",
       "25        Portuguese Grand Prix      0.717980    0.765345       0.700862   \n",
       "26           Styrian Grand Prix      0.931581    0.517340       0.568292   \n",
       "27           Russian Grand Prix      1.187672    0.820455       1.021635   \n",
       "28           Turkish Grand Prix      1.544040    0.944235       1.405239   \n",
       "29  70th Anniversary Grand Prix      0.798335    0.703501       0.845582   \n",
       "30            Tuscan Grand Prix      0.842235    0.844375       0.850806   \n",
       "31             Eifel Grand Prix      0.699898    0.818247       0.685291   \n",
       "32            Sakhir Grand Prix      0.410202    0.786357       0.394023   \n",
       "33            German Grand Prix      2.061848    0.914527       2.029391   \n",
       "34           Mexican Grand Prix      0.833429    0.790207       0.834176   \n",
       "35         Brazilian Grand Prix      1.078337    0.524845       1.070953   \n",
       "\n",
       "    LightGBM_R2 Best_Model  \n",
       "0      0.858803    XGBoost  \n",
       "1      0.729435    XGBoost  \n",
       "2      0.956135    XGBoost  \n",
       "3      0.922305    XGBoost  \n",
       "4      0.850484   LightGBM  \n",
       "5      0.864483   LightGBM  \n",
       "6      0.937857    XGBoost  \n",
       "7      0.939366   LightGBM  \n",
       "8      0.973832   LightGBM  \n",
       "9      0.825490    XGBoost  \n",
       "10     0.649412   LightGBM  \n",
       "11     0.911383   LightGBM  \n",
       "12     0.834455   LightGBM  \n",
       "13     0.923163    XGBoost  \n",
       "14     0.935140    XGBoost  \n",
       "15     0.935799   LightGBM  \n",
       "16     0.815540    XGBoost  \n",
       "17     0.979154   LightGBM  \n",
       "18     0.823877   LightGBM  \n",
       "19     0.885336   LightGBM  \n",
       "20     0.922897   LightGBM  \n",
       "21     0.823710    XGBoost  \n",
       "22     0.903613   LightGBM  \n",
       "23     0.993553   LightGBM  \n",
       "24     0.899156   LightGBM  \n",
       "25     0.776401   LightGBM  \n",
       "26     0.820385   LightGBM  \n",
       "27     0.867147   LightGBM  \n",
       "28     0.953810   LightGBM  \n",
       "29     0.667368    XGBoost  \n",
       "30     0.841192    XGBoost  \n",
       "31     0.825754   LightGBM  \n",
       "32     0.802878   LightGBM  \n",
       "33     0.917197   LightGBM  \n",
       "34     0.789830    XGBoost  \n",
       "35     0.531330   LightGBM  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Model Performance by Circuit ---\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8672de8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Model Performance Summary ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_models_trained': 36,\n",
       " 'average_rmse': np.float64(0.9165628292469629),\n",
       " 'average_r2': np.float64(0.8636081762386086)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Final Model Performance Summary ---\")\n",
    "final_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
